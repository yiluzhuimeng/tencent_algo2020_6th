{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:21:49,255 - INFO - PyTorch version 1.1.0 available.\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "f = F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import datetime\n",
    "import pickle\n",
    "import scipy.sparse as ss\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "# import seaborn as sns\n",
    "\n",
    "import IPython.display as ipd\n",
    "import copy\n",
    "import random\n",
    "# from pandarallel import pandarallel\n",
    "# Initialization\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "# df.parallel_apply(func)\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "\n",
    "from transformers import *\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm.notebook import tqdm \n",
    "from transformers.modeling_bert import BertConfig, BertEncoder, BertAttention,\\\n",
    "BertSelfAttention,BertLayer,BertPooler,BertLayerNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dir = '../../var'\n",
    "my_var_dir = '../../var/hyr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:21:50,451 - INFO - start read df data\n",
      "2020-07-23 09:23:35,899 - INFO - finish read df data\n"
     ]
    }
   ],
   "source": [
    "logging.info('start read df data')\n",
    "\n",
    "df_train_user = pd.read_csv('%s/data/train_semi_final/user.csv'% var_dir)\n",
    "pre_df_train_user = pd.read_csv('%s/data/train_preliminary/user.csv'% var_dir)\n",
    "df_train_user = pd.concat([pre_df_train_user, df_train_user])\n",
    "\n",
    "train_user = list(range(1, 3000001))\n",
    "test_user = list(range(3000001, 4000001))\n",
    "\n",
    "train_gender = np.array(list(df_train_user['gender']))\n",
    "train_age = np.array(list(df_train_user['age']))\n",
    "id_embedding_feq = np.load('%s/id_embedding_wv_short.npy'%my_var_dir)\n",
    "se_tfidf_stack = pickle.load(open('%s/se_tfidf_stack_new.pickle'%my_var_dir, 'rb'))\n",
    "df_user_info = pickle.load(open('%s/df_user_info.pickle'%my_var_dir, 'rb'))\n",
    "target_encode_user_dict, mp_target_encode = pickle.load(open('%s/target_info_new.pickle'%my_var_dir, 'rb'))\n",
    "\n",
    "logging.info('finish read df data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offline = df_train_user.shape[0] < 30000\n",
    "if offline:\n",
    "    train_user = list(range(1, 301))\n",
    "    test_user = list(range(3000001, 3000101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "ARG = namedtuple('ARG', [\n",
    "    'batch_size',\n",
    "    'epoch', \n",
    "    'lr',\n",
    "    'weight_decay',\n",
    "    'debug',\n",
    "    'n_embedding',\n",
    "    'max_length',\n",
    "    'n_eval',\n",
    "    'n_worker',\n",
    "    'device',\n",
    "    \n",
    "    'n_gpu',\n",
    "    'card_list',\n",
    "    \n",
    "    'n_fold',\n",
    "    'save_path',\n",
    "])\n",
    " \n",
    "args = ARG(\n",
    "    batch_size = 64 if offline else 256,\n",
    "    epoch = 10,\n",
    "    lr = 0.003,\n",
    "    weight_decay = 0.,\n",
    "    debug = False,\n",
    "    n_embedding = 100,\n",
    "    max_length = 128,\n",
    "    n_eval = 100000,\n",
    "    n_worker = 1,\n",
    "    device=torch.device(\"cuda:1\"),\n",
    "#     device=torch.device(\"cpu\"),\n",
    "\n",
    "    n_gpu = 2,\n",
    "    card_list = [0, 1],\n",
    "    \n",
    "    n_fold = 5,\n",
    "    save_path = '%s/model_one_50dim_wv_lr0003_wd0_dp02/' % my_var_dir,\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "if args.debug:\n",
    "    debug_number = 2000\n",
    "    sub_train_user = train_user[:debug_number]\n",
    "    sub_train_gender = train_gender[:debug_number] - 1\n",
    "    sub_train_age = train_age[:debug_number] - 1\n",
    "    sub_test_user = test_user[:debug_number]\n",
    "else:\n",
    "    sub_train_user = train_user\n",
    "    sub_train_gender = train_gender - 1\n",
    "    sub_train_age = train_age - 1\n",
    "    sub_test_user = test_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AdDataset(Data.Dataset):\n",
    "    def __init__(self, user_ids, gender = None, age = None):\n",
    "        self.user_id = list(user_ids)\n",
    "        self.gender = gender if gender is not None else [-1 for _ in range(len(self.user_id))]\n",
    "        self.age = age if age is not None else [-1 for _ in range(len(self.user_id))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.user_id)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return [self.user_id[idx], self.gender[idx], self.age[idx]]\n",
    "    \n",
    "feature_name = ['ad_id', 'product_category', 'advertiser_id', 'industry']\n",
    "\n",
    "n_embedding = 50\n",
    "x_dict = {\n",
    "    'time' :  np.zeros((args.batch_size, args.max_length)).astype('int'),\n",
    "    'click_time' :  np.zeros((args.batch_size, args.max_length)).astype('int'),\n",
    "\n",
    "    'creative_id' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'ad_id' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_id' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'), \n",
    "    'product_category' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'), \n",
    "    'advertiser_id' :  np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32') , \n",
    "    'industry' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    \n",
    "    'advertiser_id_industry' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_category_advertiser_id' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_category_industry' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_id_advertiser_id' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_id_industry' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    'product_id_product_category' : np.zeros((args.batch_size, args.max_length, n_embedding)).astype('float32'),\n",
    "    \n",
    "    'x_len' :  np.zeros((args.batch_size,)).astype('long'),\n",
    "}\n",
    "\n",
    "\n",
    "x_target_encode = np.zeros((args.batch_size, args.max_length, 72)).astype('float32')\n",
    "def collate_fn(samples):\n",
    "    sample_np = np.array(samples)\n",
    "    user_ids = sample_np[:, 0]\n",
    "    gender = sample_np[:, 1]\n",
    "    age = sample_np[:, 2]\n",
    "    \n",
    "    \n",
    "    for i, user in enumerate(user_ids):\n",
    "        S = time.time()\n",
    "\n",
    "        df_user_info_sub = df_user_info.loc[user]\n",
    "        creative_ids = df_user_info_sub['creative_id'][:args.max_length]\n",
    "\n",
    "        len_data = len(creative_ids)\n",
    "\n",
    "        x_dict['time'][i][:len_data] = df_user_info_sub['time'][:len_data]\n",
    "        x_dict['click_time'][i][:len_data] = df_user_info_sub['click_time'][:len_data]\n",
    "                \n",
    "        flod = target_encode_user_dict[user]\n",
    "        x_target_encode[i][:len_data] = np.array(list(mp_target_encode[flod].loc[creative_ids]))\n",
    "\n",
    "        id_embeddings = id_embedding_feq[creative_ids]\n",
    "\n",
    "        x_dict['ad_id'][i][:len_data] = id_embeddings[:, :50]\n",
    "        x_dict['creative_id'][i][:len_data] = id_embeddings[:, 50:100]\n",
    "        x_dict['product_id_product_category'][i][:len_data] = id_embeddings[:, 100:150]\n",
    "        x_dict['advertiser_id'][i][:len_data] = id_embeddings[:, 150:200]\n",
    "        x_dict['advertiser_id_industry'][i][:len_data] = id_embeddings[:, 200:250]\n",
    "        x_dict['product_category_advertiser_id'][i][:len_data] = id_embeddings[:, 250:300]\n",
    "        x_dict['product_id_advertiser_id'][i][:len_data] = id_embeddings[:, 300:350]\n",
    "\n",
    "        x_dict['x_len'][i] = len_data\n",
    "        \n",
    "\n",
    "    len_user = sample_np.shape[0]\n",
    "    \n",
    "#     cat_feature = torch.cat([torch.tensor(x_dict['ad_id'][:len_user]), torch.tensor(x_dict['product_category'][:len_user]),\n",
    "#                             torch.tensor(x_dict['advertiser_id'][:len_user]), torch.tensor(x_dict['industry'][:len_user])], dim = 2)\n",
    "    \n",
    "\n",
    "    if gender[0] == -1:\n",
    "        gender = None\n",
    "        age = None\n",
    "    else:\n",
    "        gender = torch.tensor(gender)\n",
    "        age = torch.tensor(age)\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'time' : torch.tensor(x_dict['time'][:len_user]).long(),\n",
    "        'click_time' : torch.tensor(x_dict['click_time'][:len_user]).long(),\n",
    "        \n",
    "        'creative_id' : torch.tensor(x_dict['creative_id'][:len_user]),\n",
    "        'ad_id' : torch.tensor(x_dict['ad_id'][:len_user]),\n",
    "        'advertiser_id' : torch.tensor(x_dict['advertiser_id'][:len_user]), \n",
    "        \n",
    "        'advertiser_id_industry' : torch.tensor(x_dict['advertiser_id_industry'][:len_user]),\n",
    "        'product_category_advertiser_id' : torch.tensor(x_dict['product_category_advertiser_id'][:len_user]),\n",
    "        'product_id_advertiser_id' : torch.tensor(x_dict['product_id_advertiser_id'][:len_user]),\n",
    "        'product_id_product_category' : torch.tensor(x_dict['product_id_product_category'][:len_user]),\n",
    "        \n",
    "\n",
    "        'target_encode_sequence' : torch.tensor(x_target_encode[:len_user]).float(),\n",
    "        \n",
    "        'x_len' :  torch.tensor(x_dict['x_len'][:len_user]),\n",
    "        'x_flatten' : torch.tensor(list(se_tfidf_stack[user_ids].values)).float(),\n",
    "        'gender' : gender,\n",
    "        'age' : age,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     31,
     43
    ]
   },
   "outputs": [],
   "source": [
    "TIME_FORWARD = 0\n",
    "TIME_BACKWARD = 0\n",
    "    \n",
    "\n",
    "def predict_batch_multi_task(model, user_ids, batch_size = args.batch_size):\n",
    "    len_user_ids = len(user_ids)\n",
    "    pre_list_gender = []\n",
    "    pre_list_age = []\n",
    "    pre_list_hidden = []\n",
    "    \n",
    "    train_dataset=AdDataset(user_ids)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=train_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(tqdm(data_loader)):\n",
    "            pre_gender, pre_age, pre_hidden = model(**data)\n",
    "            pre_list_gender.append(pre_gender.cpu().detach().numpy())\n",
    "            pre_list_age.append(pre_age.cpu().detach().numpy())      \n",
    "            pre_list_hidden.append(pre_hidden.cpu().detach().numpy())\n",
    "            \n",
    "    return {\n",
    "        'gender' : np.concatenate(pre_list_gender), \n",
    "        'age' : np.concatenate(pre_list_age),\n",
    "    }\n",
    "\n",
    "def eval_data(model, user_ids, gender_labels, age_labels):\n",
    "    choose_idx = list(range(len(user_ids)))\n",
    "    if(len(user_ids) > args.n_eval):\n",
    "        choose_idx = random.sample(choose_idx, args.n_eval)\n",
    "    ret_dict = predict_batch_multi_task(model, user_ids[choose_idx])\n",
    "\n",
    "    predict_gender = np.argmax(ret_dict['gender'], axis = 1)\n",
    "    predict_age = np.argmax(ret_dict['age'], axis = 1)\n",
    "    acc_gender = accuracy_score(gender_labels[choose_idx], predict_gender)\n",
    "    acc_age = accuracy_score(age_labels[choose_idx], predict_age)\n",
    "    return acc_gender, acc_age\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "def train_multi_task(n_fold, model_class, class_parms, train_dataset, val_dataset, test_user_id):\n",
    "    \n",
    "    global TIME_FORWARD, TIME_BACKWARD, best_score\n",
    "    best_score = 0\n",
    "\n",
    "    train_user_id = train_dataset['x']\n",
    "    train_gender = train_dataset['gender']\n",
    "    train_age = train_dataset['age']\n",
    "    \n",
    "    logging.info('train number %d, val number %d' % (len(train_user_id), len(val_dataset['x'])))\n",
    "    \n",
    "    torch_dataset = AdDataset(train_user_id, train_gender, train_age)\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=torch_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    \n",
    "    model = model_class(**class_parms).to(args.device)\n",
    "            \n",
    "    \n",
    "    no_decay = [\"bias\", \"gamma\",\"beta\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr = args.lr, weight_decay = args.weight_decay)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=int(len(train_user_id)//(args.batch_size)), num_training_steps=int(len(train_user_id) / args.batch_size * args.epoch)\n",
    "    )\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        loss_list, loss_gender_list, loss_age_list = [], [], []\n",
    "        model.train()\n",
    "        \n",
    "        for step, data in enumerate(tqdm(data_loader)):\n",
    "            #forward\n",
    "            S = time.time()\n",
    "\n",
    "            loss, loss_gender, loss_age, pre_gender, pre_age, _ = model(**data)\n",
    "        \n",
    "            TIME_FORWARD += time.time() - S\n",
    "            \n",
    "            loss_list.append(float(loss))\n",
    "            loss_gender_list.append(float(loss_gender))\n",
    "            loss_age_list.append(float(loss_age))\n",
    "            \n",
    "            #backward\n",
    "            S = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 5)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            TIME_BACKWARD += time.time() - S\n",
    "        \n",
    "        model.eval()\n",
    "\n",
    "        train_acc_gender, train_acc_age = eval_data(model, train_dataset['x'], train_dataset['gender'], train_dataset['age'])\n",
    "\n",
    "        val_acc_gender, val_acc_age = eval_data(model, val_dataset['x'], val_dataset['gender'], val_dataset['age'])\n",
    "        \n",
    "        if(val_acc_gender + val_acc_age > best_score):\n",
    "            torch.save(model, '%s/model_%d_best' % (args.save_path, n_fold))\n",
    "            best_score = val_acc_gender + val_acc_age\n",
    "\n",
    "        \n",
    "        logging.info('forward:%f backward:%f'%(TIME_FORWARD,TIME_BACKWARD))\n",
    "        logging.info(\"flod %d epoch %d : \\n loss: %f loss_gender : %f, loss_age : %f, gender : %f, %f, age : %f, %f, score:%f\" %\\\n",
    "                     (n_fold, epoch, np.mean(loss_list), np.mean(loss_gender_list), np.mean(loss_age_list), \\\n",
    "                      train_acc_gender, val_acc_gender, train_acc_age, val_acc_age, val_acc_gender + val_acc_age))\n",
    "    \n",
    "    \n",
    "    if(best_score - val_acc_gender - val_acc_age > 0.00001):\n",
    "        model = torch.load('%s/model_%d_best' % (args.save_path, n_fold))\n",
    "        \n",
    "    val_ret_dict = predict_batch_multi_task(model, val_dataset['x'])\n",
    "    test_ret_dict = predict_batch_multi_task(model, test_user_id)\n",
    "    \n",
    "    return model, val_ret_dict, test_ret_dict\n",
    "\n",
    "\n",
    "def nn_cross_validation_multi_task(x_train, gender, age, x_test, model_class, class_parms, func_train, is_cross = True, random_seed = 0):\n",
    "    \n",
    "    folds = KFold(n_splits=args.n_fold, shuffle=False)\n",
    "    \n",
    "    if os.path.exists(args.save_path) == False:\n",
    "        os.mkdir(args.save_path)\n",
    "    \n",
    "    x_train_val = np.array(x_train)\n",
    "    gender_train_val = np.array(gender)\n",
    "    age_train_val = np.array(age)\n",
    "\n",
    "\n",
    "    score_gender_val = np.zeros((len(x_train), 2))\n",
    "    score_age_val = np.zeros((len(x_train), 10))\n",
    "    \n",
    "    for n_fold, (trn_idx, val_idx) in enumerate(folds.split(x_train, gender_train_val)):\n",
    "        save_trn_idx = trn_idx\n",
    "        save_val_idx = val_idx\n",
    "        \n",
    "        train_x, train_gender, train_age = x_train_val[trn_idx], gender_train_val[trn_idx], age_train_val[trn_idx]\n",
    "        val_x, val_gender, val_age = x_train_val[val_idx], gender_train_val[val_idx], age_train_val[val_idx]\n",
    "        train_dataset = {\n",
    "            'x' : train_x,\n",
    "            'gender' : train_gender,\n",
    "            'age' : train_age,\n",
    "        }\n",
    "        val_dataset = {\n",
    "            'x' : val_x,\n",
    "            'gender' : val_gender,\n",
    "            'age' : val_age\n",
    "        }\n",
    "        \n",
    "        model, val_ret_dict, test_ret_dict = func_train(n_fold, model_class, class_parms, train_dataset, val_dataset, x_test)\n",
    "        \n",
    "        score_gender_val[val_idx] = val_ret_dict['gender']\n",
    "        score_age_val[val_idx] = val_ret_dict['age']\n",
    "        \n",
    "        val_predict_gender = np.argmax(score_gender_val[val_idx] , axis = 1)\n",
    "        val_predict_age = np.argmax(score_age_val[val_idx] , axis = 1)\n",
    "\n",
    "        if is_cross == False:\n",
    "            eda_val_dict = {\n",
    "                'user' : val_x,\n",
    "                'pre_gender' : val_predict_gender,\n",
    "                'gender' : val_gender,\n",
    "                'pre_age' : val_predict_age,\n",
    "                'age' : val_age,\n",
    "                'score_gender' : score_gender_val[val_idx],\n",
    "                'score_age' :  score_age_val[val_idx]\n",
    "            }\n",
    "\n",
    "            return model, eda_val_dict, test_ret_dict\n",
    "        \n",
    "        acc_gender = accuracy_score(val_gender, val_predict_gender)\n",
    "        acc_age = accuracy_score(val_age, val_predict_age)\n",
    "\n",
    "        logging.info(\"%d : gender : %f, age: %f, score :%f\" % (n_fold, acc_gender, acc_age, acc_gender + acc_age))\n",
    "\n",
    "        torch.save(model, '%s/model_%d' % (args.save_path, n_fold))\n",
    "        pickle.dump(test_ret_dict, open('%s/test_dict_flod_%d.pickle' % (args.save_path, n_fold), 'wb'))\n",
    "        \n",
    "        test_gender_pre = np.argmax(test_ret_dict['gender'], axis = 1) + 1\n",
    "        test_age_pre = np.argmax(test_ret_dict['age'], axis = 1) + 1\n",
    "        df_submit = pd.DataFrame()\n",
    "        df_submit['user_id'] = x_test\n",
    "        df_submit['predicted_gender'] = test_gender_pre\n",
    "        df_submit['predicted_age'] = test_age_pre\n",
    "        df_submit.to_csv('%s/df_submit_flod_%d.csv' % (args.save_path, n_fold), index=False)\n",
    "        \n",
    "        \n",
    "    return score_gender_val, score_age_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0,
     11,
     15,
     33,
     53,
     70,
     78,
     82,
     96,
     122,
     135,
     154,
     194,
     247
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:24:25,755 - INFO - start training \n",
      "2020-07-23 09:24:25,757 - INFO - train number 240, val number 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cacdd87a52d4d97bceb0c052bfc8fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2969a002220a4b788578035e4a5b7227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc5314cb25b481db0673e59ff71e526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RE2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type LayerNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type RE2One. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type AlignmentOne. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Conv1d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type GeLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type FullFusion. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type AugmentedResidual. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Pooling. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "2020-07-23 09:24:47,509 - INFO - forward:0.251570 backward:0.225411\n",
      "2020-07-23 09:24:47,511 - INFO - flod 0 epoch 0 : \n",
      " loss: 2.101092 loss_gender : 1.509389, loss_age : 2.692795, gender : 0.620833, 0.600000, age : 0.170833, 0.216667, score:0.816667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e2c60bcc0f4d76899da88710dbe292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9b27434bd6466ebe26bda41b5004fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c9103a10fa434ab9d401730fac7435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:24:51,025 - INFO - forward:0.299351 backward:0.397007\n",
      "2020-07-23 09:24:51,026 - INFO - flod 0 epoch 1 : \n",
      " loss: 3.345638 loss_gender : 4.028987, loss_age : 2.662289, gender : 0.620833, 0.600000, age : 0.204167, 0.100000, score:0.700000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6fd98dd02b4a15aa5ca4e4bf1b6b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce75f59e24e047afae682e9d80e85af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f3b845088343d5a31741510a5a439a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:24:54,253 - INFO - forward:0.325073 backward:0.574116\n",
      "2020-07-23 09:24:54,255 - INFO - flod 0 epoch 2 : \n",
      " loss: 1.696451 loss_gender : 0.872600, loss_age : 2.520302, gender : 0.379167, 0.400000, age : 0.125000, 0.133333, score:0.533333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1672b56b0feb466eacd7a687f83612bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cf60b25f664df6bc6d0cfe364fec5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49735bf8d9e4ce58e738470db8cb46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:24:56,998 - INFO - forward:0.353511 backward:0.753920\n",
      "2020-07-23 09:24:57,000 - INFO - flod 0 epoch 3 : \n",
      " loss: 2.491407 loss_gender : 2.674332, loss_age : 2.308481, gender : 0.379167, 0.400000, age : 0.170833, 0.150000, score:0.550000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d236d97e24c547dba94050da1e12f367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da6332bf3554630962140e3922ff565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c54f742f34482b8a6bbcc88015d509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:24:59,434 - INFO - forward:0.390170 backward:0.929072\n",
      "2020-07-23 09:24:59,436 - INFO - flod 0 epoch 4 : \n",
      " loss: 2.162421 loss_gender : 2.016120, loss_age : 2.308721, gender : 0.379167, 0.400000, age : 0.179167, 0.166667, score:0.566667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21aa8fec4216463daba08463e23e6153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3366f8144e9242f5b878e3c31a140216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6c1222462743bb9323fa50e7694589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:25:02,299 - INFO - forward:0.417786 backward:1.105451\n",
      "2020-07-23 09:25:02,300 - INFO - flod 0 epoch 5 : \n",
      " loss: 1.630728 loss_gender : 0.977659, loss_age : 2.283798, gender : 0.620833, 0.600000, age : 0.175000, 0.150000, score:0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3c3ac425c54ca7896ceb10226f83e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 09:25:03,016 - ERROR - Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "2020-07-23 09:25:03,043 - INFO - \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 377, in <module>\n",
      "    RE2, {'args' : re2_args}, train_multi_task, True)\n",
      "  File \"<ipython-input-7-fa636a3296bd>\", line 164, in nn_cross_validation_multi_task\n",
      "    model, val_ret_dict, test_ret_dict = func_train(n_fold, model_class, class_parms, train_dataset, val_dataset, x_test)\n",
      "  File \"<ipython-input-7-fa636a3296bd>\", line 89, in train_multi_task\n",
      "    loss, loss_gender, loss_age, pre_gender, pre_age, _ = model(**data)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 330, in forward\n",
      "    hidden = self.re2_one(a_wv, x_len)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 183, in forward\n",
      "    a_enc = block['encoder'](a, mask_a)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 50, in forward\n",
      "    x = encoder(x)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 32, in forward\n",
      "    return torch.cat([encoder(x) for encoder in self.model], dim=-1)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 32, in <listcomp>\n",
      "    return torch.cat([encoder(x) for encoder in self.model], dim=-1)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/container.py\", line 92, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 493, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-8-2a52e4d3a634>\", line 14, in forward\n",
      "    return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super(LayerNorm,self).__init__()\n",
    "        self.gamma=nn.Parameter(torch.ones(features))\n",
    "        self.beta=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "    def forward(self,X):\n",
    "        mean=X.mean(-1,keepdim=True)\n",
    "        std=X.std(-1,keepdim=True)\n",
    "        return self.gamma*(X-mean)/(std+self.eps)+self.beta\n",
    "    \n",
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Conv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_sizes):\n",
    "        super().__init__()\n",
    "        assert all(k % 2 == 1 for k in kernel_sizes), 'only support odd kernel sizes'\n",
    "        assert out_channels % len(kernel_sizes) == 0, 'out channels must be dividable by kernels'\n",
    "        out_channels = out_channels // len(kernel_sizes)\n",
    "        convs = []\n",
    "        for kernel_size in kernel_sizes:\n",
    "            conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                             padding=(kernel_size - 1) // 2)\n",
    "            nn.init.normal_(conv.weight, std=math.sqrt(2. / (in_channels * kernel_size)))\n",
    "            nn.init.zeros_(conv.bias)\n",
    "            convs.append(nn.Sequential(nn.utils.weight_norm(conv), GeLU()))\n",
    "        self.model = nn.ModuleList(convs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([encoder(x) for encoder in self.model], dim=-1)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, args, input_size):\n",
    "        super().__init__()\n",
    "        self.dropout = args.dropout\n",
    "        self.encoders = nn.ModuleList([Conv1d(\n",
    "                in_channels=input_size if i == 0 else args.hidden_size,\n",
    "                out_channels=args.hidden_size,\n",
    "                kernel_sizes=args.kernel_sizes) for i in range(args.enc_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = x.transpose(1, 2)  # B x C x L\n",
    "        mask = mask.transpose(1, 2)\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            x.masked_fill_(~mask, 0.)\n",
    "            if i > 0:\n",
    "                x = f.dropout(x, self.dropout, self.training)\n",
    "            x = encoder(x)\n",
    "        x = f.dropout(x, self.dropout, self.training)\n",
    "        return x.transpose(1, 2)  # B x L x C\n",
    "    \n",
    "class FullFusion(nn.Module):\n",
    "    def __init__(self, args, input_size):\n",
    "        super().__init__()\n",
    "        self.dropout = args.dropout\n",
    "        self.fusion1 = Linear(input_size * 2, args.hidden_size, activations=True)\n",
    "        self.fusion2 = Linear(input_size * 2, args.hidden_size, activations=True)\n",
    "        self.fusion3 = Linear(input_size * 2, args.hidden_size, activations=True)\n",
    "        self.fusion = Linear(args.hidden_size * 3, args.hidden_size, activations=True)\n",
    "\n",
    "    def forward(self, x, align):\n",
    "        x1 = self.fusion1(torch.cat([x, align], dim=-1))\n",
    "        x2 = self.fusion2(torch.cat([x, x - align], dim=-1))\n",
    "        x3 = self.fusion3(torch.cat([x, x * align], dim=-1))\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "        x = f.dropout(x, self.dropout, self.training)\n",
    "        return self.fusion(x)\n",
    "    \n",
    "class AugmentedResidual(nn.Module):\n",
    "    def forward(self, x, res, i):\n",
    "        if i == 1:\n",
    "            return torch.cat([x, res], dim=-1)  # res is embedding\n",
    "        hidden_size = x.size(-1)\n",
    "        x = (res[:, :, :hidden_size] + x) * math.sqrt(0.5)\n",
    "        return torch.cat([x, res[:, :, hidden_size:]], dim=-1)  # latter half of res is embedding\n",
    "    \n",
    "class Pooling(nn.Module):\n",
    "    def forward(self, x, mask):\n",
    "        return x.masked_fill_(~mask, -float('inf')).max(dim=1)[0]\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, activations=False):\n",
    "        super().__init__()\n",
    "        linear = nn.Linear(in_features, out_features)\n",
    "        nn.init.normal_(linear.weight, std=math.sqrt((2. if activations else 1.) / in_features))\n",
    "        nn.init.zeros_(linear.bias)\n",
    "        modules = [nn.utils.weight_norm(linear)]\n",
    "        if activations:\n",
    "            modules.append(GeLU())\n",
    "        self.model = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Alignment(nn.Module):\n",
    "    def __init__(self, args, __):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.tensor(1 / math.sqrt(args.hidden_size)))\n",
    "        self.summary = {}\n",
    "\n",
    "    def _attention(self, a, b):\n",
    "        return torch.matmul(a, b.transpose(1, 2)) * self.temperature\n",
    "    \n",
    "    def add_summary(self, name, val):\n",
    "        if self.training:\n",
    "            self.summary[name] = val.clone().detach().cpu().numpy()\n",
    "\n",
    "    def forward(self, a, b, mask_a, mask_b):\n",
    "        attn = self._attention(a, b)\n",
    "        mask = torch.matmul(mask_a.float(), mask_b.transpose(1, 2).float()).byte()\n",
    "        attn.masked_fill_(~mask, -1e7)\n",
    "        attn_a = f.softmax(attn, dim=1)\n",
    "        attn_b = f.softmax(attn, dim=2)\n",
    "        feature_b = torch.matmul(attn_a.transpose(1, 2), a)\n",
    "        feature_a = torch.matmul(attn_b, b)\n",
    "        self.add_summary('temperature', self.temperature)\n",
    "        self.add_summary('attention_a', attn_a)\n",
    "        self.add_summary('attention_b', attn_b)\n",
    "        return feature_a, feature_b\n",
    "\n",
    "class MappedAlignment(Alignment):\n",
    "    def __init__(self, args, input_size):\n",
    "        super().__init__(args, input_size)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Dropout(args.dropout),\n",
    "            Linear(input_size, args.hidden_size, activations=True),\n",
    "        )\n",
    "\n",
    "    def _attention(self, a, b):\n",
    "        a = self.projection(a)\n",
    "        b = self.projection(b)\n",
    "        return super()._attention(a, b)\n",
    "\n",
    "class AlignmentOne(nn.Module):\n",
    "    def __init__(self, args, __):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.tensor(1 / math.sqrt(args.hidden_size)))\n",
    "        self.summary = {}\n",
    "\n",
    "    def _attention(self, a):\n",
    "        return torch.matmul(a, a.transpose(1, 2)) * self.temperature\n",
    "    \n",
    "\n",
    "    def forward(self, a, mask_a):\n",
    "        attn = self._attention(a)\n",
    "#         mask = torch.matmul(mask_a.float(), mask_a.transpose(1, 2).float()).byte()\n",
    "        mask = mask_a.byte()\n",
    "        attn.masked_fill_(~mask, -1e7)\n",
    "        attn_a = f.softmax(attn, dim=1)\n",
    "        feature_a = torch.matmul(attn_a.transpose(1, 2), a)\n",
    "        return feature_a\n",
    "\n",
    "class RE2One(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.dropout = args.dropout\n",
    "        self.blocks = nn.ModuleList([nn.ModuleDict({\n",
    "            'encoder': Encoder(args, args.embedding_dim if i == 0 else args.embedding_dim + args.hidden_size),\n",
    "            'alignment': AlignmentOne(\n",
    "                args, args.embedding_dim + args.hidden_size if i == 0 else args.embedding_dim + args.hidden_size * 2),\n",
    "            'fusion': FullFusion(\n",
    "                args, args.embedding_dim + args.hidden_size if i == 0 else args.embedding_dim + args.hidden_size * 2),\n",
    "        }) for i in range(args.blocks)])\n",
    "        self.connection = AugmentedResidual()\n",
    "        self.pooling = Pooling()\n",
    "            \n",
    "    def make_mask(self, X, valid_len):\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "        mask=(torch.arange(0,X.shape[1]).repeat(X.shape[0],1).to(X.device)<valid_len).float()\n",
    "        return mask.unsqueeze(2).byte()\n",
    "\n",
    "    def forward(self, a, x_len):\n",
    "        mask_a = self.make_mask(a, x_len)\n",
    "        res_a = a\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i > 0:\n",
    "                a = self.connection(a, res_a, i)\n",
    "                res_a = a\n",
    "            a_enc = block['encoder'](a, mask_a)\n",
    "            a = torch.cat([a, a_enc], dim=-1)\n",
    "            align_a = block['alignment'](a, mask_a)\n",
    "            a = block['fusion'](a, align_a)        \n",
    "        \n",
    "\n",
    "        hidden= self.pooling(a, mask_a)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return hidden\n",
    "    \n",
    "class RE2Block(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.dropout = args.dropout\n",
    "        self.blocks = nn.ModuleList([nn.ModuleDict({\n",
    "            'encoder': Encoder(args, args.embedding_dim if i == 0 else args.embedding_dim + args.hidden_size),\n",
    "            'alignment': MappedAlignment(\n",
    "                args, args.embedding_dim + args.hidden_size if i == 0 else args.embedding_dim + args.hidden_size * 2),\n",
    "            'fusion': FullFusion(\n",
    "                args, args.embedding_dim + args.hidden_size if i == 0 else args.embedding_dim + args.hidden_size * 2),\n",
    "        }) for i in range(args.blocks)])\n",
    "        self.connection = AugmentedResidual()\n",
    "        self.pooling = Pooling()\n",
    "        \n",
    "        \n",
    "#         self.ln_100s = nn.ModuleList([LayerNorm(100) for _ in range(24)])\n",
    "    \n",
    "    def make_mask(self, X, valid_len):\n",
    "        shape=X.shape\n",
    "        if valid_len.dim()==1:\n",
    "            valid_len=valid_len.view(-1,1).repeat(1,shape[1])\n",
    "        mask=(torch.arange(0,X.shape[1]).repeat(X.shape[0],1).to(X.device)<valid_len).float()\n",
    "        return mask.unsqueeze(2).byte()\n",
    "       \n",
    "\n",
    "    def forward(self, a, b, x_len):\n",
    "        mask_a = self.make_mask(a, x_len)\n",
    "        mask_b = self.make_mask(b, x_len)\n",
    "        \n",
    "        res_a, res_b = a, b\n",
    "        \n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i > 0:\n",
    "                a = self.connection(a, res_a, i)\n",
    "                b = self.connection(b, res_b, i)\n",
    "                res_a, res_b = a, b\n",
    "            a_enc = block['encoder'](a, mask_a)\n",
    "            b_enc = block['encoder'](b, mask_b)\n",
    "            a = torch.cat([a, a_enc], dim=-1)\n",
    "            b = torch.cat([b, b_enc], dim=-1)\n",
    "            align_a, align_b = block['alignment'](a, b, mask_a, mask_b)\n",
    "            a = block['fusion'](a, align_a)\n",
    "            b = block['fusion'](b, align_b)\n",
    "        \n",
    "        \n",
    "\n",
    "        a = self.pooling(a, mask_a)\n",
    "        b = self.pooling(b, mask_b)\n",
    "        \n",
    "        hidden = torch.cat([a, b, (a - b).abs(), a * b], dim=-1) #symmetric\n",
    "        \n",
    "        return hidden\n",
    "\n",
    "class RE2(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        n_dim = 50\n",
    "        self.ln_tfidf_stack = LayerNorm(55)\n",
    "        self.ln_one_hot_target = LayerNorm(72)\n",
    "\n",
    "        n_time_embedding = 16\n",
    "        self.position_embeddings = nn.Embedding(92, n_time_embedding)\n",
    "        self.click_time_embeddings = nn.Embedding(33, n_time_embedding)\n",
    "\n",
    "        self.ln_50s = nn.ModuleList([LayerNorm(50) for _ in range(14)])\n",
    "        \n",
    "        \n",
    "        n_cat_hidden = 1\n",
    "        n_flatten = 55\n",
    "        self.decoder_gender = nn.Sequential(Linear( n_cat_hidden * args.hidden_size + n_flatten, 2))\n",
    "        self.decoder_age = nn.Sequential(Linear(n_cat_hidden * args.hidden_size + n_flatten, 10))   \n",
    "        \n",
    "\n",
    "        self.ln_hidden = LayerNorm(n_cat_hidden * args.hidden_size)\n",
    "        self.ln_tfidf_stack = LayerNorm(55)\n",
    "        self.ln_target_agg = LayerNorm(360)\n",
    "\n",
    "        \n",
    "        self.re2_one = RE2One(args)\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                time,\n",
    "                click_time,\n",
    "                \n",
    "                creative_id,\n",
    "                ad_id,\n",
    "                advertiser_id,                \n",
    "                advertiser_id_industry,\n",
    "                product_category_advertiser_id,\n",
    "                product_id_advertiser_id,\n",
    "                product_id_product_category,\n",
    "                \n",
    "                target_encode_sequence,\n",
    "                x_len,\n",
    "                x_flatten,\n",
    "                gender = None,\\\n",
    "                age = None):\n",
    "        \n",
    "        \n",
    "        time = time.to(args.device)\n",
    "        click_time = click_time.to(args.device)\n",
    "        \n",
    "        creative_id = creative_id.to(args.device) \n",
    "        ad_id = ad_id.to(args.device) \n",
    "        advertiser_id = advertiser_id.to(args.device) \n",
    "        advertiser_id_industry = advertiser_id_industry.to(args.device)\n",
    "        product_category_advertiser_id = product_category_advertiser_id.to(args.device) \n",
    "        product_id_advertiser_id = product_id_advertiser_id.to(args.device)\n",
    "        product_id_product_category = product_id_product_category.to(args.device) \n",
    "        \n",
    "        target_encode_sequence = target_encode_sequence.to(args.device) \n",
    "        x_len = x_len.to(args.device) \n",
    "        x_flatten = x_flatten.to(args.device)\n",
    "        \n",
    "        if gender is not None:\n",
    "            gender = gender.to(args.device) \n",
    "            age = age.to(args.device) \n",
    "    \n",
    "        \n",
    "        a_wv = torch.cat([\n",
    "            self.ln_50s[0](ad_id),\n",
    "            self.ln_50s[1](creative_id),\n",
    "            self.ln_50s[2](product_id_product_category),\n",
    "            self.ln_50s[3](advertiser_id),\n",
    "            self.ln_50s[4](advertiser_id_industry),\n",
    "            self.ln_50s[5](product_category_advertiser_id),\n",
    "            self.ln_50s[6](product_id_advertiser_id),\n",
    "\n",
    "            self.ln_one_hot_target(target_encode_sequence),\n",
    "            self.position_embeddings(time),\n",
    "            self.click_time_embeddings(click_time),\n",
    "        ],dim=-1)\n",
    "\n",
    "        \n",
    "        hidden = self.re2_one(a_wv, x_len)\n",
    "        cat = torch.cat([self.ln_hidden(hidden), self.ln_tfidf_stack(x_flatten)], dim = -1)\n",
    "        output_age = self.decoder_age(cat)\n",
    "        output_gender = self.decoder_gender(cat)\n",
    "\n",
    "        if(gender is None):\n",
    "            return output_gender, output_age, hidden\n",
    "        \n",
    "        \n",
    "        loss_age = nn.CrossEntropyLoss()\n",
    "        loss_gender = nn.CrossEntropyLoss()\n",
    "        l_age = loss_age(output_age,age.long())        \n",
    "        l_gender = loss_gender(output_gender,gender.long())\n",
    "            \n",
    "        \n",
    "        l=0.5*l_gender + 0.5*l_age\n",
    "        \n",
    "        \n",
    "        return l,l_gender,l_age,output_gender, output_age, hidden\n",
    "\n",
    "\n",
    "RE2_ARG = namedtuple('ARG', [\n",
    "    'dropout',\n",
    "    'hidden_size',\n",
    "    'enc_layers',\n",
    "    'kernel_sizes',\n",
    "    'blocks',\n",
    "    'embedding_dim',\n",
    "    'device',\n",
    "])\n",
    "\n",
    "re2_args = RE2_ARG(\n",
    "    dropout = 0.2,\n",
    "    hidden_size = 256,\n",
    "    enc_layers = 2,\n",
    "    kernel_sizes = (3,),\n",
    "    blocks = 2,\n",
    "    embedding_dim = 350 + 72 + 16 + 16,\n",
    "    device = args.device,\n",
    ")\n",
    "\n",
    "model = RE2(re2_args)\n",
    "print(sum(param.numel() for param in model.parameters()))\n",
    "\n",
    "logging.info('start training ')\n",
    "score_gender_val, score_age_val = nn_cross_validation_multi_task(sub_train_user, sub_train_gender, sub_train_age,\\\n",
    "                                                                    sub_test_user, \\\n",
    "                                                                    RE2, {'args' : re2_args}, train_multi_task, True)\n",
    "\n",
    "pickle.dump(score_gender_val, open('%s/score_gender_val.pickle' % args.save_path, 'wb'))\n",
    "pickle.dump(score_age_val, open('%s/score_age_val.pickle' % args.save_path, 'wb'))\n",
    "# logging.info('finish training ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjw",
   "language": "python",
   "name": "fjw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
