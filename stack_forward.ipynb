{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from category_encoders import *\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import scipy\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import pickle\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "import os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.special import softmax\n",
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# paths = []\n",
    "# names = []\n",
    "# target_dir = './var/model_ret_dicts/hyr/'\n",
    "# for filename in os.listdir(target_dir):\n",
    "#     if(filename[0] == '.'):\n",
    "#         continue\n",
    "#     paths.append(target_dir + filename)\n",
    "#     names.append(filename)\n",
    "    \n",
    "# target_dir = './var/model_ret_dicts/fjw/'\n",
    "# for filename in os.listdir(target_dir):\n",
    "#     if(filename[0] == '.') :\n",
    "#         continue\n",
    "#     paths.append(target_dir + filename)\n",
    "#     names.append(filename)\n",
    "# names = list(map(lambda x : x.replace('model_', '') ,names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_ret_dicts = []\n",
    "# logging.info(\"loading feature...\") \n",
    "# for p in paths:\n",
    "#     ret = pickle.load(open(p, 'rb'))\n",
    "#     model_ret_dicts.append(ret)\n",
    "# logging.info(\"loading finished...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x = np.zeros((1000000, 12 * len(model_ret_dicts))).astype('float32')\n",
    "# for i in range(len(model_ret_dicts)):\n",
    "                  \n",
    "#     test_x[:, i*12:i*12+2] = model_ret_dicts[i]['test_gender']                  \n",
    "#     test_x[:, i*12+2:i*12+12] = model_ret_dicts[i]['test_age']                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 404)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class_20_test_np = np.load('./var/model_ret_dicts/class20_test.npy')\n",
    "# test_x = np.concatenate([test_x, class_20_test_np], axis=1)\n",
    "# test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-23 14:59:14,223 - INFO - PyTorch version 1.1.0 available.\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from transformers import *\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x=np.load(\"./var/test_x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ARG = namedtuple('ARG', [\n",
    "    'batch_size',\n",
    "    'epoch',\n",
    "    'lr',\n",
    "    'weight_decay',\n",
    "    'n_worker',\n",
    "    'device',\n",
    "    'n_fold'\n",
    "])\n",
    " \n",
    "args = ARG(\n",
    "    batch_size = 1024,\n",
    "    epoch = 10,\n",
    "    lr = 0.005,\n",
    "    weight_decay = 0.1,\n",
    "    n_worker = 0,\n",
    "    n_fold = 5,\n",
    "    device=torch.device(\"cuda:3\"),\n",
    "#     device=torch.device(\"cpu\"),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1. + torch.tanh(x * 0.7978845608 * (1. + 0.044715 * x * x)))\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        in_feature = 12 * 32+20\n",
    "        \n",
    "        hidden = 324\n",
    "        out_feature = 256\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_feature, hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden, out_feature),\n",
    "        )\n",
    "        self.decode_gender = nn.Linear(out_feature, 2)\n",
    "        self.decode_age = nn.Linear(out_feature, 10)\n",
    "   \n",
    "    def forward(self, x, gender = None, age = None):\n",
    "        \n",
    "        hidden = self.dense(x)\n",
    "        output_gender = self.decode_gender(hidden)\n",
    "        output_age = self.decode_age(hidden)\n",
    "        \n",
    "        if gender is None:\n",
    "            return output_gender, output_age\n",
    "        \n",
    "        ce = nn.CrossEntropyLoss()\n",
    "        loss_gender = ce(output_gender, gender.long())\n",
    "        loss_age = ce(output_age, age.long())\n",
    "        loss = loss_gender + loss_age\n",
    "        return loss, loss_gender, loss_age, output_gender, output_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def swa(logger, model, model_dir, model_path_list, swa_start):\n",
    "    \"\"\"\n",
    "    :param logger: ...\n",
    "    :param model: ...\n",
    "    :param model_dir: ...\n",
    "    :param model_path_list: this model path list should be increased by steps\n",
    "    :param swa_start: the epoch when averaging begins. (start with 0)\n",
    "    :return: model path list extend with swa model\n",
    "    \"\"\"\n",
    "\n",
    "    assert 1 < swa_start <= len(model_path_list) - 1, \\\n",
    "        f'Using swa, swa start should smaller than {len(model_path_list) - 1} and bigger than 1'\n",
    "\n",
    "    swa_model = copy.deepcopy(model)\n",
    "    swa_n = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ckpt in model_path_list[swa_start:]:\n",
    "            logger.info(f'Load model from {_ckpt}')\n",
    "            model.load_state_dict(torch.load(os.path.join(model_dir, _ckpt, 'model.pt'),\n",
    "                                             map_location=torch.device('cpu')))\n",
    "            tmp_para_dict = dict(model.named_parameters())\n",
    "\n",
    "            alpha = 1. / (swa_n + 1.)\n",
    "\n",
    "            for name, para in swa_model.named_parameters():\n",
    "                para.copy_(tmp_para_dict[name].data.clone() * alpha + para.data.clone() * (1. - alpha))\n",
    "\n",
    "            swa_n += 1\n",
    "\n",
    "    swa_model_dir = os.path.join(model_dir, f'checkpoint-swa_start{swa_start}')\n",
    "    if not os.path.exists(swa_model_dir):\n",
    "        os.mkdir(swa_model_dir)\n",
    "\n",
    "    logger.info('Save swa model')\n",
    "\n",
    "    torch.save(swa_model.state_dict(), os.path.join(swa_model_dir, 'model.pt'))\n",
    "\n",
    "    model_path_list.append(f'checkpoint-swa_start{swa_start}')\n",
    "\n",
    "    return model_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangweilin/anaconda3/envs/fjw/lib/python3.6/site-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a7a4b4a4fd4ac4a593aff1a7e3b527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95f7d5f0e1340ce8daad31763745db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3da09abaa644ebbee3a083ea378d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be76083ab1bf44208828e021379b7b29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9119901594914c85a326444d37faa036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=977), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"../model/\"\n",
    "def predict_batch_multi_task(model, train_x, batch_size = args.batch_size):\n",
    "    len_user_ids = len(train_x)\n",
    "    pre_list_gender = []\n",
    "    pre_list_age = []\n",
    "    \n",
    "    train_dataset = Data.TensorDataset(torch.tensor(train_x).float())\n",
    "    data_loader = Data.DataLoader(\n",
    "        dataset=train_dataset,      \n",
    "        batch_size=args.batch_size,      \n",
    "        shuffle=False,\n",
    "        num_workers = args.n_worker,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for step, data in enumerate(tqdm(data_loader)):\n",
    "            \n",
    "            pre_gender, pre_age = model(data[0].to(args.device))\n",
    "            pre_list_gender.append(pre_gender.cpu().detach().numpy())\n",
    "            pre_list_age.append(pre_age.cpu().detach().numpy())      \n",
    "        model.train()\n",
    "    return {\n",
    "        'gender' : np.concatenate(pre_list_gender), \n",
    "        'age' : np.concatenate(pre_list_age),\n",
    "    }\n",
    "    \n",
    "test_gender = np.zeros((len(test_x), 2))\n",
    "test_age = np.zeros((len(test_x), 10))\n",
    "for fold in range(args.n_fold):\n",
    "    \n",
    "    model=Dense().to(args.device)\n",
    "    model.load_state_dict(torch.load(\"./model/model_\"+str(fold+1)+\".pt\"))\n",
    "    test_ret_dict=predict_batch_multi_task(model,test_x)\n",
    "    test_gender += softmax(test_ret_dict['gender'], axis=1) / args.n_fold\n",
    "    test_age += softmax(test_ret_dict['age'], axis=1) / args.n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gender_pre = np.argmax(test_gender, axis = 1) + 1\n",
    "test_age_pre = np.argmax(test_age, axis = 1) + 1\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit['user_id'] = list(range(3000001, 4000001))\n",
    "df_submit['predicted_gender'] = test_gender_pre\n",
    "df_submit['predicted_age'] = test_age_pre\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fjw",
   "language": "python",
   "name": "fjw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
